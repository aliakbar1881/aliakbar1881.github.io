{
    "hero": {
        "title": "توضیح‌پذیری هوش‌مصنوعی",
        "description": "سیستمی برای افزایش آگاهی و کنترل کاربر در فرآیند استنتاج مدل.",
        "button_text": "بیشتر بدانید",
        "button_link": "#features"
    },
    "features": [
        {
            "icon": "fas fa-eye",
            "title": "شفافیت در استنتاج",
            "description": "تولید مدل‌هایی که به صورت پیش‌فرض افزایش اطلاع کاربر از جزئیات فرایند آموزش و استنتاج را در نظر می‌گیرند."
        },
        {
            "icon": "fas fa-pen",
            "title": "امکان تغییر در فرایند استنتاج",
            "description": "ایجاد امکان تغییر در ابعاد مختلف تصمیم‌گیری مدل مانند انتخاب داده‌ها یا ویژگی‌های تاثیرگذار در خروجی مدل."
        },
        {
            "icon": "fas fa-gauge-high",
            "title": "بازده و کارایی بالا",
            "description": "ارتقا و یا حفظ سرعت و دقت مدل توضیح‌پذیر در عین ایجاد امکان توضیح‌پذیری، و عبور از دوگانه‌ی شفافیت در مقابل کارایی."
        }
    ],
    "projects": [
        {
            "title": "هوش‌مصنوعی توضیح‌پذیر بالفعل",
            "description": "ترکیبی از یادگیری عمیق و یادگیری تنبل به ما اجازه‌ی دخالت در داده‌های تاثیرگذار را میدهد.",
            "progress": 80,
            "progress_in_persian": "۸۰",
            "features": [
                "توضیح‌پذیری با پیدا کردن سهم تاثیر هر نمونه در داده‌های آموزش",
                "امکان ایجاد تغییر در سهم تاثیر هر نمونه بدون نیاز به آموزش مجدد مدل",
                "مد‌های پیش‌بینی کننده"
            ],
            "todo": [
                "مدل‌های مولد"
            ],
            "github_link": "https://github.com/aliakbar1881/IpsofactoModel"
        },
        {
            "title": "توضیح‌پذیری بالفعل با داده‌های خوشه‌ای",
            "description": "ترکیب مدل‌های RAG با مدل‌های توضیح‌پذیر بالفعل برای سرعت و شخصی‌سازی.",
            "progress": 0,
            "progress_in_persian": "۰",
            "todo": [
                "پیاده سازی الگوریتم جستجوی سریع در پایگاه داده",
                "توضیح‌پذیری بالفعل با استفاده از داده‌های نزدیک",
                "استفاده از الگوریتم‌های جستجوی سریع (مانند KNN) در آموزش و استنتاج با در نظر گرفتن سهم اهمیت (و نه لزوماً شباهت و نزدیکی)"
            ],
            "github_link": "https://github.com/aliakbar1881/IpsofactoModel"
        }
    ],
    "testimonial": {
        "text": "در این پروژه، توانسته‌ایم نشان دهیم که استنتاج مدل نه‌تنها قابل توضیح به کاربر است، بلکه به‌صورت بالفعل می‌توان فرایند آن را شفاف‌سازی کرد. همچنین، امکان ورود اراده‌ی کاربر به جریان استنتاج هوش مصنوعی را فراهم کرده‌ایم، به‌ویژه در مرحله‌ی انتخاب داده‌های تأثیرگذار. این رویکرد در حال گسترش به سایر بخش‌های فرایند استنتاج نیز هست.\n\nهدف ما این است که ابزارهای جدید جایگزین متخصصان انسانی نشوند، بلکه بتوانند از طریق تعامل مؤثر با کاربر، تصمیم‌گیری را بهبود بخشند. برای تحقق این امر، ابزار طراحی‌شده باید بتواند اراده و تصمیمات کاربر را در چارچوبی ساختاریافته مدل‌سازی کرده و در استنتاج لحاظ کند. این امر به لطف شفافیت در استنتاج مدل محقق می‌شود و لازم است که این شفافیت در ابعاد دیگر نیز گسترش یابد، ازجمله در نحوه‌ی تغییرات داده‌های آموزشی و ارزیابی مدل.\n\nبا این رویکرد، به سمت سیستمی حرکت می‌کنیم که نه‌تنها دقت و کارایی استنتاج را بهبود می‌بخشد، بلکه تعامل انسانی را نیز در قلب فرایند تصمیم‌گیری حفظ می‌کند."
    }
}
